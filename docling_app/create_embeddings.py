#!/usr/bin/env python3
"""
Ð¡ÐºÑ€Ð¸Ð¿Ñ‚ Ð´Ð»Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¾Ð² Ð¸Ð· Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð² Qdrant
"""

import os
import json
import requests
import hashlib
from pathlib import Path

OLLAMA_URL = "http://ollama-docling:11434"
QDRANT_URL = "http://qdrant-docling:6333"
COLLECTION_NAME = "documents"

def get_embedding(text: str, model: str = "nomic-embed-text"):
    """ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÑ‚ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³ Ñ‚ÐµÐºÑÑ‚Ð° Ñ‡ÐµÑ€ÐµÐ· Ollama"""
    try:
        response = requests.post(
            f"{OLLAMA_URL}/api/embeddings",
            json={"model": model, "prompt": text},
            timeout=60
        )
        response.raise_for_status()
        return response.json()["embedding"]
    except Exception as e:
        print(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð°: {e}")
        return None

def chunk_text(text: str, chunk_size: int = 500, overlap: int = 50):
    """Ð Ð°Ð·Ð±Ð¸Ð²Ð°ÐµÑ‚ Ñ‚ÐµÐºÑÑ‚ Ð½Ð° Ñ‡Ð°Ð½ÐºÐ¸ Ñ Ð¿ÐµÑ€ÐµÐºÑ€Ñ‹Ñ‚Ð¸ÐµÐ¼"""
    words = text.split()
    chunks = []
    
    for i in range(0, len(words), chunk_size - overlap):
        chunk = " ".join(words[i:i + chunk_size])
        if chunk:
            chunks.append(chunk)
    
    return chunks

def add_to_qdrant(doc_id: str, embedding: list, text: str, metadata: dict):
    """Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÑ‚ Ð²ÐµÐºÑ‚Ð¾Ñ€ Ð² Qdrant"""
    try:
        response = requests.put(
            f"{QDRANT_URL}/collections/{COLLECTION_NAME}/points",
            json={
                "points": [{
                    "id": doc_id,
                    "vector": embedding,
                    "payload": {
                        "text": text,
                        **metadata
                    }
                }]
            },
            timeout=30
        )
        response.raise_for_status()
        return True
    except Exception as e:
        print(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ð² Qdrant: {e}")
        return False

def process_file(file_path: str):
    """ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ñ„Ð°Ð¹Ð» Ð¸ ÑÐ¾Ð·Ð´Ð°ÐµÑ‚ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¸"""
    print(f"\n{'='*60}")
    print(f"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ°: {file_path}")
    print(f"{'='*60}")
    
    # Ð§Ð¸Ñ‚Ð°ÐµÐ¼ Ñ„Ð°Ð¹Ð»
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    if not content.strip():
        print("âš ï¸  Ð¤Ð°Ð¹Ð» Ð¿ÑƒÑÑ‚Ð¾Ð¹, Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼")
        return
    
    # Ð Ð°Ð·Ð±Ð¸Ð²Ð°ÐµÐ¼ Ð½Ð° Ñ‡Ð°Ð½ÐºÐ¸
    chunks = chunk_text(content)
    print(f"ðŸ“„ Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¾ Ñ‡Ð°Ð½ÐºÐ¾Ð²: {len(chunks)}")
    
    filename = Path(file_path).name
    
    # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ ÐºÐ°Ð¶Ð´Ñ‹Ð¹ Ñ‡Ð°Ð½Ðº
    for idx, chunk in enumerate(chunks):
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ð¹ ID
        chunk_id = hashlib.md5(f"{filename}_{idx}".encode()).hexdigest()
        
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³
        print(f"  [{idx+1}/{len(chunks)}] Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð°... ", end="")
        embedding = get_embedding(chunk)
        
        if embedding:
            # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð² Qdrant
            metadata = {
                "filename": filename,
                "chunk_index": idx,
                "total_chunks": len(chunks)
            }
            
            if add_to_qdrant(chunk_id, embedding, chunk, metadata):
                print("âœ…")
            else:
                print("âŒ")
        else:
            print("âŒ")
    
    print(f"âœ¨ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð°!\n")

def process_directory(input_dir: str):
    """ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ð²ÑÐµ markdown Ñ„Ð°Ð¹Ð»Ñ‹ Ð² Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸"""
    files = list(Path(input_dir).glob("*.md"))
    
    if not files:
        print(f"âš ï¸  ÐÐµÑ‚ .md Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð² {input_dir}")
        return
    
    print(f"\nðŸš€ ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸: {len(files)}")
    
    for file_path in files:
        process_file(str(file_path))

if __name__ == "__main__":
    import sys
    
    input_path = sys.argv[1] if len(sys.argv) > 1 else "/shared/processed"
    
    if os.path.isfile(input_path):
        process_file(input_path)
    else:
        process_directory(input_path)

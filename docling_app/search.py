#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
"""

import sys
import os
import requests

OLLAMA_URL = "http://ollama-docling:11434"
QDRANT_URL = "http://qdrant-docling:6333"
COLLECTION_NAME = "documents"

# OpenRouter API
OPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY', '')
OPENROUTER_URL = "https://openrouter.ai/api/v1/chat/completions"
DEEPSEEK_MODEL = "deepseek/deepseek-chat"

def get_embedding(text: str, model: str = "nomic-embed-text"):
    """–ü–æ–ª—É—á–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞"""
    response = requests.post(
        f"{OLLAMA_URL}/api/embeddings",
        json={"model": model, "prompt": text},
        timeout=60
    )
    return response.json()["embedding"]

def search(query: str, limit: int = 5):
    """–ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫: semantic + keyword + boosting"""
    print(f"\nüîç –ü–æ–∏—Å–∫: {query}\n")
    
    query_lower = query.lower()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    doc_filters = {
        '—Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫': '–°–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –ú—É–¥—Ä–æ–≥–æ –†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è',
        '–∑–æ–ª–æ—Ç–æ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç': '–ó–æ–ª–æ—Ç–æ–π –°—Ç–∞–Ω–¥–∞—Ä—Ç –ê—É–¥–∏—Ç–∞',
        '–¥–∏—Ä–µ–∫—Ç–æ—Ä': '–î–∏—Ä–µ–∫—Ç–æ—Ä'
    }
    
    search_filter = None
    for keyword, doc_pattern in doc_filters.items():
        if keyword in query_lower:
            search_filter = {
                "must": [{
                    "key": "filename",
                    "match": {"text": doc_pattern}
                }]
            }
            print(f"üéØ –§–∏–ª—å—Ç—Ä –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç—É: {doc_pattern}")
            break
    
    # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–∞
    print("‚åõ –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∑–∞–ø—Ä–æ—Å–∞...")
    query_embedding = get_embedding(query)
    
    # –ò—â–µ–º –≤ Qdrant
    print("‚åõ –ü–æ–∏—Å–∫ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ...\n")
    
    search_params = {
        "vector": query_embedding,
        "limit": limit * 2 if not search_filter else limit,
        "with_payload": True
    }
    if search_filter:
        search_params["filter"] = search_filter
    
    response = requests.post(
        f"{QDRANT_URL}/collections/{COLLECTION_NAME}/points/search",
        json=search_params,
        timeout=30
    )
    
    results = response.json()["result"]
    
    if not results:
        print("‚ùå –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        return []
    
    # Keyword matching + boosting
    query_lower = query.lower()
    keyword_boosts = {
        '—Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫': ('–°–ø—Ä–∞–≤–æ—á–Ω–∏–∫', 0.3),
        '–∑–æ–ª–æ—Ç–æ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç': ('–ó–æ–ª–æ—Ç–æ–π –°—Ç–∞–Ω–¥–∞—Ä—Ç', 0.3),
        '—Å—Å–ø': ('–°–ø—Ä–∞–≤–æ—á–Ω–∏–∫', 0.2),
        '–ø–∏—Ä': ('–ü–ò–†', 0.05),
        '–¥–∏—Ä–µ–∫—Ç–æ—Ä': ('–î–∏—Ä–µ–∫—Ç–æ—Ä', 0.1)
    }
    
    # Re-ranking
    for result in results:
        filename = result["payload"]["filename"]
        total_chunks = result["payload"]["total_chunks"]
        
        # Keyword boost
        for keyword, (file_pattern, boost) in keyword_boosts.items():
            if keyword in query_lower and file_pattern in filename:
                result["score"] += boost
        
        # Small doc boost (<100 chunks)
        if total_chunks < 100:
            result["score"] += 0.05
    
    # –ü–µ—Ä–µ—Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞
    results.sort(key=lambda x: x["score"], reverse=True)
    results = results[:limit]
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(results)}\n")
    print("="*80)
    
    for idx, result in enumerate(results, 1):
        score = result["score"]
        payload = result["payload"]
        
        print(f"\nüìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç #{idx} (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {score:.3f})")
        print(f"   –§–∞–π–ª: {payload.get('filename', 'N/A')}")
        print(f"   –ß–∞–Ω–∫: {payload.get('chunk_index', 0) + 1}/{payload.get('total_chunks', 1)}")
        print(f"\n   {payload['text'][:300]}...")
        print("\n" + "-"*80)
    
    return results

def ask_llm(query: str, context: str, model: str = "deepseek"):
    """–°–ø—Ä–∞—à–∏–≤–∞–µ—Ç LLM —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º"""
    system_prompt = """–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç-–∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –¥–∞–≤–∞—Ç—å –†–ê–ó–í–ï–†–ù–£–¢–´–ï –∏ –¢–û–ß–ù–´–ï –æ—Ç–≤–µ—Ç—ã.

–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û - –ò–ó–ë–ï–ì–ê–ô –ì–ê–õ–õ–Æ–¶–ò–ù–ê–¶–ò–ô:
1. –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
2. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç - —Ç–∞–∫ –∏ —Å–∫–∞–∂–∏, –ù–ï –î–û–ú–´–®–õ–Ø–ô
3. –¶–∏—Ç–∏—Ä—É–π —Ç–æ—á–Ω—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
4. –£–∫–∞–∑—ã–≤–∞–π –∏—Å—Ç–æ—á–Ω–∏–∫ (–∏–∑ –∫–∞–∫–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞)

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê:
1. –ü–æ–ª–Ω—ã–π —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–π –æ—Ç–≤–µ—Ç (10-15 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π)
2. –†–∞—Å–∫—Ä—ã–≤–∞–π –≤—Å–µ –∞—Å–ø–µ–∫—Ç—ã –≤–æ–ø—Ä–æ—Å–∞
3. –ü—Ä–∏–≤–æ–¥–∏ –ø—Ä–∏–º–µ—Ä—ã –∏ –¥–µ—Ç–∞–ª–∏ –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
4. –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –æ—Ç–≤–µ—Ç –ø–æ –ø—É–Ω–∫—Ç–∞–º
5. –ù–ï –ò–°–ü–û–õ–¨–ó–£–ô markdown (*, #, **)
6. –ò—Å–ø–æ–ª—å–∑—É–π —Ç–∏—Ä–µ –∏ —Ü–∏—Ñ—Ä—ã –¥–ª—è —Å–ø–∏—Å–∫–æ–≤
7. –í –∫–æ–Ω—Ü–µ: 2-3 —É—Ç–æ—á–Ω—è—é—â–∏—Ö –≤–æ–ø—Ä–æ—Å–∞"""
    
    user_prompt = f"""–ö–æ–Ω—Ç–µ–∫—Å—Ç:
{context}

–í–æ–ø—Ä–æ—Å: {query}

–û—Ç–≤–µ—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞:"""
    
    print("\nü§ñ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ (DeepSeek)...\n")
    
    try:
        response = requests.post(
            OPENROUTER_URL,
            headers={
                "Authorization": f"Bearer {OPENROUTER_API_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "model": DEEPSEEK_MODEL,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ]
            },
            timeout=120
        )
        response.raise_for_status()
        answer = response.json()["choices"][0]["message"]["content"]
    except Exception as e:
        print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ DeepSeek API: {e}")
        print("üîÑ Fallback –Ω–∞ Ollama...\n")
        try:
            response = requests.post(
                f"{OLLAMA_URL}/api/generate",
                json={
                    "model": "llama3.2",
                    "prompt": f"{system_prompt}\n\n{user_prompt}",
                    "stream": False
                },
                timeout=180
            )
            answer = response.json()["response"]
        except Exception as e2:
            answer = f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {str(e2)}"
    
    print(f"üí¨ –û—Ç–≤–µ—Ç:\n{answer}\n")
    return answer

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python search.py <–≤–∞—à_–∑–∞–ø—Ä–æ—Å>")
        sys.exit(1)
    
    query = " ".join(sys.argv[1:])
    
    # –ò—â–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
    results = search(query, limit=10)
    
    if results:
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context = "\n\n".join([r["payload"]["text"] for r in results])
        
        # –°–ø—Ä–∞—à–∏–≤–∞–µ–º LLM
        ask_llm(query, context)

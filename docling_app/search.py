#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
"""

import sys
import os
import requests

OLLAMA_URL = "http://ollama-docling:11434"
QDRANT_URL = "http://qdrant-docling:6333"
COLLECTION_NAME = "documents"

# OpenRouter API
OPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY', '')
OPENROUTER_URL = "https://openrouter.ai/api/v1/chat/completions"
DEEPSEEK_MODEL = "deepseek/deepseek-chat"

def get_embedding(text: str, model: str = "nomic-embed-text"):
    """–ü–æ–ª—É—á–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞"""
    response = requests.post(
        f"{OLLAMA_URL}/api/embeddings",
        json={"model": model, "prompt": text},
        timeout=60
    )
    return response.json()["embedding"]

def search(query: str, limit: int = 5):
    """–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    print(f"\nüîç –ü–æ–∏—Å–∫: {query}\n")
    
    # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–∞
    print("‚è≥ –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∑–∞–ø—Ä–æ—Å–∞...")
    query_embedding = get_embedding(query)
    
    # –ò—â–µ–º –≤ Qdrant
    print("‚è≥ –ü–æ–∏—Å–∫ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ...\n")
    response = requests.post(
        f"{QDRANT_URL}/collections/{COLLECTION_NAME}/points/search",
        json={
            "vector": query_embedding,
            "limit": limit,
            "with_payload": True
        },
        timeout=30
    )
    
    results = response.json()["result"]
    
    if not results:
        print("‚ùå –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        return []
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(results)}\n")
    print("="*80)
    
    for idx, result in enumerate(results, 1):
        score = result["score"]
        payload = result["payload"]
        
        print(f"\nüìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç #{idx} (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {score:.3f})")
        print(f"   –§–∞–π–ª: {payload.get('filename', 'N/A')}")
        print(f"   –ß–∞–Ω–∫: {payload.get('chunk_index', 0) + 1}/{payload.get('total_chunks', 1)}")
        print(f"\n   {payload['text'][:300]}...")
        print("\n" + "-"*80)
    
    return results

def ask_llm(query: str, context: str, model: str = "deepseek"):
    """–°–ø—Ä–∞—à–∏–≤–∞–µ—Ç LLM —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º"""
    system_prompt = """–¢—ã - –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –∞–Ω–∞–ª–∏–∑—É –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.

–ü–†–ê–í–ò–õ–ê –û–¢–í–ï–¢–ê:
1. –ü–∏—à–∏ –ö–†–ê–¢–ö–û –∏ –ü–û –°–£–¢–ò - –º–∞–∫—Å–∏–º—É–º 5-7 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
2. –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–Ω–∏–∫–∞–∫–∏—Ö –¥–æ–¥–æ–º—ã—Å–ª–æ–≤!)
3. –ü–∏—à–∏ –Ω–∞ —á–∏—Å—Ç–æ–º —Ä—É—Å—Å–∫–æ–º, –±–µ–∑ –∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã—Ö —Å–ª–æ–≤
4. –ù–ï –ò–°–ü–û–õ–¨–ó–£–ô markdown —Å–∏–º–≤–æ–ª—ã (*, #, ###, **)
5. –†–∞–∑–±–∏–≤–∞–π –æ—Ç–≤–µ—Ç –Ω–∞ –∫–æ—Ä–æ—Ç–∫–∏–µ –∞–±–∑–∞—Ü—ã (2-3 —Å—Ç—Ä–æ–∫–∏)
6. –î–ª—è —Å–ø–∏—Å–∫–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–π —Ç–∏—Ä–µ –∏ —Ü–∏—Ñ—Ä—ã (1., 2., -)
7. –í –∫–æ–Ω—Ü–µ –ø—Ä–µ–¥–ª–æ–∂–∏ 2-3 —É—Ç–æ—á–Ω—è—é—â–∏—Ö –≤–æ–ø—Ä–æ—Å–∞

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê:
–ö–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å.

–û—Å–Ω–æ–≤–Ω—ã–µ –ø—É–Ω–∫—Ç—ã —Å –ø–æ—è—Å–Ω–µ–Ω–∏—è–º–∏.

–£—Ç–æ—á–Ω—è—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã:
- –í–æ–ø—Ä–æ—Å 1?
- –í–æ–ø—Ä–æ—Å 2?"""
    
    user_prompt = f"""–ö–æ–Ω—Ç–µ–∫—Å—Ç:
{context}

–í–æ–ø—Ä–æ—Å: {query}

–û—Ç–≤–µ—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞:"""
    
    print("\nü§ñ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ (DeepSeek)...\n")
    
    try:
        response = requests.post(
            OPENROUTER_URL,
            headers={
                "Authorization": f"Bearer {OPENROUTER_API_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "model": DEEPSEEK_MODEL,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ]
            },
            timeout=120
        )
        response.raise_for_status()
        answer = response.json()["choices"][0]["message"]["content"]
    except Exception as e:
        print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ DeepSeek API: {e}")
        print("üîÑ Fallback –Ω–∞ Ollama...\n")
        response = requests.post(
            f"{OLLAMA_URL}/api/generate",
            json={
                "model": "llama3.2",
                "prompt": f"{system_prompt}\n\n{user_prompt}",
                "stream": False
            },
            timeout=120
        )
        answer = response.json()["response"]
    
    print(f"üí¨ –û—Ç–≤–µ—Ç:\n{answer}\n")
    return answer

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python search.py <–≤–∞—à_–∑–∞–ø—Ä–æ—Å>")
        sys.exit(1)
    
    query = " ".join(sys.argv[1:])
    
    # –ò—â–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
    results = search(query, limit=3)
    
    if results:
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context = "\n\n".join([r["payload"]["text"] for r in results])
        
        # –°–ø—Ä–∞—à–∏–≤–∞–µ–º LLM
        ask_llm(query, context)
